name: immich

# Volumes #####################################################################
volumes:
  immich-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: "${UPLOAD_LOCATION}"

  immich-external:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: "${EXTERNAL_LOCATION}"

  postgres-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: "${DB_DATA_LOCATION}"

  caddy-data:
  model-cache:
  prometheus-data:
  grafana-data:

# Networks ####################################################################
networks:
  net:
    driver: bridge
    attachable: true

# Services ####################################################################
services:
  immich-server:
    container_name: immich_server
    image: ghcr.io/immich-app/immich-server:${IMMICH_VERSION:-release}
    extends:
      file: hwaccel.transcoding.yml
      service: nvenc # set to one of [nvenc, quicksync, rkmpp, vaapi, vaapi-wsl] for accelerated transcoding
    build:
      context: ../
      dockerfile: server/Dockerfile
    volumes:
      - immich-data:/usr/src/app/upload
      - /etc/localtime:/etc/localtime:ro
      - immich-external:/external:ro
    env_file:
      - .env
    # ports:
    #   - 2283:2283
    depends_on:
      - redis
      - database
    restart: always
    networks:
      - net
    healthcheck:
      disable: false

  immich-machine-learning:
    container_name: immich_machine_learning
    image: ghcr.io/immich-app/immich-machine-learning:${IMMICH_VERSION:-release}-cuda
    extends:
      file: hwaccel.ml.yml
      service: cuda # set to one of [armnn, cuda, openvino, openvino-wsl] for accelerated inference
    build:
      context: ../machine-learning
      dockerfile: Dockerfile
      args:
        - DEVICE=cuda # set to one of [armnn, cuda, openvino, openvino-wsl] for accelerated inference
    # ports:
    #   - 3003:3003
    volumes:
      - model-cache:/cache
    env_file:
      - .env
    restart: always
    networks:
      - net
    healthcheck:
      disable: false

  redis:
    container_name: immich_redis
    image: docker.io/redis:6.2-alpine@sha256:2ba50e1ac3a0ea17b736ce9db2b0a9f6f8b85d4c27d5f5accc6a416d8f42c6d5
    networks:
      - net
    healthcheck:
      test: redis-cli ping || exit 1
    restart: always

  database:
    container_name: immich_postgres
    image: tensorchord/pgvecto-rs:pg14-v0.2.0@sha256:90724186f0a3517cf6914295b5ab410db9ce23190a2d9d0b9dd6463e3fa298f0
    env_file:
      - .env
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_DB: ${DB_DATABASE_NAME}
      POSTGRES_INITDB_ARGS: '--data-checksums'
    volumes:
      - postgres-data:/var/lib/postgresql/data
    # ports:
    #   - 5432:5432
    networks:
      - net
    healthcheck:
      test: pg_isready --dbname='${DB_DATABASE_NAME}' --username='${DB_USERNAME}' || exit 1; Chksum="$$(psql --dbname='${DB_DATABASE_NAME}' --username='${DB_USERNAME}' --tuples-only --no-align --command='SELECT COALESCE(SUM(checksum_failures), 0) FROM pg_stat_database')"; echo "checksum failure count is $$Chksum"; [ "$$Chksum" = '0' ] || exit 1
      interval: 5m
      start_interval: 30s
      start_period: 5m
    command:
      [
        'postgres',
        '-c',
        'shared_preload_libraries=vectors.so',
        '-c',
        'search_path="$$user", public, vectors',
        '-c',
        'logging_collector=on',
        '-c',
        'max_wal_size=2GB',
        '-c',
        'shared_buffers=512MB',
        '-c',
        'wal_compression=on',
      ]
    restart: always

  # set IMMICH_TELEMETRY_INCLUDE=all in .env to enable metrics
  immich-prometheus:
    container_name: immich_prometheus
    # ports:
    #   - 9090:9090
    image: prom/prometheus@sha256:378f4e03703557d1c6419e6caccf922f96e6d88a530f7431d66a4c4f4b1000fe
    volumes:
    #   - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    networks:
      - net

  # first login uses admin/admin
  # add data source for http://immich-prometheus:9090 to get started
  immich-grafana:
    container_name: immich_grafana
    command: ['./run.sh', '-disable-reporting']
    # ports:
    #   - 3000:3000
    image: grafana/grafana:11.2.2-ubuntu@sha256:2bef00403c18d27919ff19d64fd6253fa713b3880304e92f69109e14221ac843
    volumes:
      - grafana-data:/var/lib/grafana
    networks:
      - net
    environment:
      GF_SERVER_DOMAIN: localhost
      GF_SERVER_ROOT_URL: "https://localhost/grafana"
      GF_SERVER_SERVE_FROM_SUB_PATH: "true"
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: changeMe

  # Caddy ---------------------------------------------------------------------
  caddy:
    image: caddy:alpine
    pull_policy: always
    restart: unless-stopped
    ports:
      - 80:80
      - 443:443
    environment:
      TLS_DOMAINS: "${TLS_DOMAINS:?TLS_DOMAINS not set}"
      ADMIN_EMAIL: "${ADMIN_EMAIL:?ADMIN_EMAIL not set}"
      CADDY_TLS: "${CADDY_TLS}"
    networks:
      - net
    volumes:
      - caddy-data:/data
      - ./caddy/Caddyfile:/etc/caddy/Caddyfile
    logging:
      options:
        max-size: ${DOCKER_LOGGING_MAX_SIZE:?DOCKER_LOGGING_MAX_SIZE not set}
        max-file: ${DOCKER_LOGGING_MAX_FILE:?DOCKER_LOGGING_MAX_FILE not set}
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "127.0.0.1:2019/metrics"]
      interval: 10s
      retries: 3
      start_period: 5s
      timeout: 5s
